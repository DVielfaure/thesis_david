\Chapter{LITERATURE REVIEW}\label{sec:RevLitt}

%Intro to the chapter

\section{Swarm Robotics}


\section{Swarm programming}

%DRONA
Drona \cite{desai2017drona} is a state-machine based language providing decentralized motion planing for mobile drones. It can be run on the Robot Operating System (ROS) and offers real-time collision-free planning even with not perfectly synchronized clocks between robots. However, Drona does not consider heterogeneous robot swarms.

%Koord
Koord \cite{ghosh2020koord}, a new programming language for distributed robotic applications draws considerable attention to verification and validation of the distributed algorithm. Koord provides abstraction from the physical robot and enables easy verification of the code. Being modular and hardware-independent, each part of the algorithm can be easily tested and validated.

%BUZZ
A programming language, specifically designed for large-scale robot swarms, has been proposed in \cite{pinciroliBuzz2016}. Buzz is an extensible programming language for Heterogeneous robot swarms offering means of easily defining swarm behaviours both from a bottom-up and top-down perspective. Of course, Buzz respects the design principles of swarm robotic systems and self-organization is assured by the fully distributed run-time platform of the language. In addition to be an accessible swarm robotics programming tool, Buzz contains a large variety of the most common swarm behaviors, such as flocking, shape formation, barriers and so on. It therefore enables fast prototyping and reduces the need of re-coding these common swarm behaviors. The swarm-oriented programming language is also integrated to ROS \cite{st2017ros}.

%ARGOS
ARGoS \cite{Pinciroli:SI2012} is a physics-based multi-robot simulator designed for large scale experiments of heterogeneous swarms. ARGoS is time efficient thanks to its capability of running robots on separate threads. Experimental results demonstrate that simulation run-time increases linearly with the number of robots. The simulator is highly customizable where the simulated environment can be divided into sub-spaces with different physics engines. Moreover, Buzz and ARGoS can work together particularly well. Swarm behaviors implemented using the Buzz programming language can be easily tested in the ARGoS simulator, even with large robot swarms. Because of the physics incorporated in the simulator, the behaviors displayed in the ARGoS usually translate well to real-world scenarios. The combination of Buzz and ARGoS provides an accessible and fast swarm robotics development tool. 






\section{Information sharing}
Distributed sensing and information sharing is not trivial, especially considering
the challenges of consistency and partial connectivity among the
robotic teams~\cite{amigoni2017multirobot,otte2018emergent}. The virtual stigmergy
presented in \cite{pinciroliTuple2016} and implemented in the Buzz
programming language \cite{pinciroliBuzz2016} achieves consensus among
a group of robots using Conflict-free Replicated Data Types (CRDTs),
represented as key-value pairs shared and replicated among the swarm members. This sort of shared data structure is
particularly relevant for belief maps, since it is easy to assign a
unique key to each cell based on its location.  In the virtual
stigmergy, data is shared on writing and reading the CRDT, with the
additional updates on read improving the robustness to temporary
disconnections and message drops. This solution differs from
distributed hash tables, which require a complete view of the system
at every point in time. Essentially, information updates are propagated throughout the swarm using the stigmergy whenever it is possible. In this sense, it offers high availability while settling for eventual data consistency. Other distributed data storage approaches such
as SwarmMesh \cite{majcherczykSwarmmesh2020} store data in different
locations based on a fitness function instead of replicating them on
all robots. This allows the storage of more data with less
communication, but robots are less likely to have access to the latest
values.

Belief maps are a simple yet powerful tool for robotic exploration
because they can represent an environment with a 2D cell grid. They
are a generalization of occupancy maps: instead of storing only one
bit per cell to indicate the presence of an obstacle/danger, they
store obstacle/danger likelihoods and offer significant improvements
for exploration \cite{stachnissMappingExplorationMobile2003}. In the
field of multi-robot exploration, early techniques leveraging belief
maps date back as far as twenty years
\cite{kobayashiSharingExploringInformation2002,kobayashiDeterminationExplorationTarget2003},
but they rely on a fixed grid size and are tested only with two
robots. More recent works also leverage belief maps for multi-robot
exploration. For example,
in~\cite{indelmanCooperativeMultirobotBelief2018}, the robots consider
both the current beliefs and the expected beliefs from future
observations to coordinate their exploration. Grid maps and belief
maps are also widely used to train deep reinforcement learning
exploration policies
\cite{hanGridWiseControlMultiAgent,panovGridPathPlanning2018}, but they often rely on a trial and error process which may select actions leading to failures \cite{garciaSafeExplorationState2012,andersenSafeReinforcementlearningIndustrial2020}.

Situational awareness \cite{jones2020distributed}
%Expliquer Davantage ....

\section{Routing}


\section{Swarm exploration strategies}
Many distributed exploration strategies maximizing the amount of
covered terrain have been proposed. The first approaches to stand out
in this regard are Voronoi-based coverage control
techniques~\cite{luo2019voronoi,santos2019decentralized}.

A second method covers time-varying domains, in which points in the
covered region can become more or less interesting to explore,
therefore prompting a change in the coverage function
\cite{santos2019decentralized,xu2019multi}. 

Another method to optimize
coverage is Frontier-Based Exploration (FBE)
\cite{yamauchi1998frontier} of which many variations have been
developed, such as those based on Particle Swarm Optimization
\cite{wang2011frontier} or the Wavefront Frontier Detector
\cite{topiwala2018frontier}. 

However, none of these strategies take
risk into account. Therefore, the
exploration strategy implemented in this paper takes inspiration of
the multi-robot control algorithm presented in
\cite{dames2012decentralized,schwagerMultirobotControlPolicy2017}
which maximizes the information gain during exploration in the
presence of unknown hazards. However, this optimal algorithm has a
very high computational complexity and could benefit from approximations.






\section{Risk in swarm robotics}
The importance of risk has dramatically increased over the last few years. Robotic systems are being used more widely and as a results risk management becomes essential as to not endanger the system itself and the objects and beings in its immediate environment. In \cite{hunt2020checklist}, a checklist for robot swarms to be safe for the public, the environment and for itself is presented. The authors draw attention to the lack of proper systematic swarm safety assessment mechanism and propose a checklist of ten questions that should be answered. They consider that swarm safety is larger than simply analyzing failure modes. Questions related to ethics, legality, accountability, security are also listed and as a results should provide a more thorough consideration of all socio-technical risks robot swarms face. 

In \cite{higgins2009threats}, the security challenges of robots swarms are presented. Security is defined as the state of being protected from risks originating from hostile and malicious intentions. The security of new technologies is usually not included in its design process, typically it is with the rise of the technology that security concerns appear. To prevent any unwanted consequences, the paper presents the security challenges robot swarms will face in an attempt of including this component in the design process of the new technology. However, only security threats are considered and risk, as something not necessarily malicious, is not examined.

Several path planners based on Markov Decision Processes \cite{undurti2010online,thiebaux2016rao,xiao2020robot} take into account risk and have useful definitions of it. In \cite{xiao2020robot}, risk is categorized into three different groups:

\begin{itemize}
    \item \textbf{Locale-Dependence:} Risk elements not depending on history. The risks associated with this category are usually location-based, in other words, it is the position of the robot in the environment that determines the level of risk. 
    \item \textbf{Action-Dependence:} Risk elements depending on close history, specifically changes of states. For example, the risk associated with an aggressive turn is tied to the last states of the robot.   
    \item \textbf{Traverse-Dependence:} Risk elements depending on the entire history of the robot. Risks associated with this category are tied to all the states traversed by the robot. For example, risk associated with low battery levels are included in the category.  
\end{itemize}

In \cite{hakobyan2019risk}, a risk-aware motion planning and decision making mechanism is presented. They automatically adjust the "conservativeness" of the motion-planner based on the risk a robot faces. The paper uses a conditional value-at-risk method used in finance to to estimate the risk of an investment. They use a safety risk measure from \cite{samuelson2018safety} onto which they apply the conditional value-at-risk method to achieve safe motion planning and control. Unfortunately, risk only includes collisions and does not translate to other types of hazards robots could face. Value at Risk strategies for robot swarms in hazardous environments was also studied in \cite{hunt2021value}. Again, the method of value-at-risk allows to quantify the foreseen loses over a period of time where the environment contains potentially damaging radiation sources. In details, agents of the swarm calculate the value-at-risk at every time step and shares it with their neighbors when their value-at-risk limit is exceeded. The information helps team members avoid dangerous locations of the environment and overall decreases exposure to risk. Some shortcomings of the method include the determination of the value-at-risk limit and the lack of instantaneous responsiveness of the method as it relies on past observations. Overall, the value-at-risk methods show that financial risk management techniques are an interesting avenue for risk-awareness in swarm robotics.

Another interesting idea for risk awareness is proposed in \cite{ono2008efficient,vitus2011feedback}, where a "risk budget" is allocated to their agents, allowing them to optimize a balance between risk and reward to guide robots. However, these systems assume a knowledge of the global state of the environment, which is unavailable when exploring unknown environments. Furthermore, most are only applied to single-robot systems. 

In SPIDER \cite{hunt2020spider}, multiple agents are tasked with chain formation in dangerous environments. They adapt to varying levels of risk to be resilient to significant failures and member losses in order to maximize information gathering. They introduce a level of "boldness" which represent the risk appetite of the agents of the swarm. This risk appetite is modulated by the connectivity of the agent, specifically its frequency of interactions of neighbors. When an agent is well-connected, its risk appetite will grow and as a result should explorer new parts of the environment. On the other hand, an agent that is isolated and far from any other members of the swarm will increasingly display a shy behavior and go back to safer regions of the environment. SPIDER effectively allows a swarm to trade-off the benefits of information gain versus robot failures. However, the problem is only studied for a chain formation scenario and risk is only a measure of how well connected is an agent.  






\section{Fault detection}

%Taxonomy and approaches
A taxonomy of the faults affecting robotic systems is presented in \cite{khalastchi2018fault}. Hardware faults affect physical components of the system. They compromise the sensing and acting abilities of the robots. Software faults affect the behaviour of the robots and are caused by faulty algorithms and/or faulty implementations. Interaction faults affect the dynamics of the robotic system and are caused by exogenous events. Hopefully, fault detection methods have been developed to mitigate the presence of faults in robotic systems. They are divided into three big families: data-driven; model-based; knowledge-based \cite{khalastchi2018fault}. 

\begin{itemize}
\item \textbf{Data-driven} approaches use sensor data and compare it to known faults, to past normal/abnormal behaviors or to the behavior of neighbour agents. Using statistical tools, data-driven approaches compute the deviation of the data and classify it as normal/abnormal depending on the extent of this deviation.  Recent data-driven approaches have applied machine learning for detecting faults. This is particularly interesting for complex systems where it is difficult to model the system and identify the informative features in the dataset.
\item \textbf{Model-based} approaches use a priori explicit model of the system to identify faults. The models are a set of analytical equations or logical formulas. When an irregularity is identified between what is observed and the theoretical model a fault is presumed. The main drawback of these approaches is the work needed in constructing the theoretical model. This is even more challenging in the robotic field where it needs to take into account the dynamic environment in which the system evolves. 
\item \textbf{Knowledge-based} approaches are similar to the way a human would perform fault detection. A fault is quickly associated with its cause. Faults are typically represented in a tree structure where the fault can be linked backwards to where it originated. It is particularly useful for fault isolation. Other knowledge-based approaches use IF-THEN structures like a human would to identify a fault and its origin. Again, the main drawback of these approaches is the need of a priori model of the system and its inefficiency in detecting faults in dynamic environments.
\end{itemize}


%Outlier detection
Outlier detection methodologies have been widely used for identifying anomalies that could be the result of a fault. A definition of “outlier” was proposed by Grubbs (Grubbs, 1969): 

\begin{center}
\textit{An outlying observation, or outlier, is one that appears to deviate
markedly from other members of the sample in which it occurs.}
\end{center} 

From this definition, we can understand that outlier detection is used for classifying data as normal or abnormal. Applying outlier detection to fault detection is to suppose that the abnormality observed is the result of a fault. Outlier detection is part of the data-driven family of the fault detection approaches.  Indeed, as we have discussed, driven approaches compute the deviation of the data and classify it as normal/abnormal depending on the extent of this deviation. From \cite{hodge2004survey}, outlier detection can be divided into 3 types: 

\begin{itemize}
    \item \textbf{Unsupervised clustering:} The outlier detection doesn’t need any prior knowledge of the data. Using the distribution of the data, the most isolated points are classified as outliers. As a result, you need to have a sufficient amount of data to start detecting outliers. Also, it requires for the data to be static, meaning that the data used for plotting the distribution should have the same value. This necessity is common for all three types of outlier detection.
    \item \textbf{Supervised classification:} The outlier detection needs a prior knowledge of normality and abnormality. Using pre-labelled normal/abnormal data, new incoming data can be classified in either of these classes based on its distance. It is also possible to have more that 2 classes. For example, you can have one normal class and two abnormal classes, with each one corresponding to a different fault. 
    \item \textbf{Semi-supervised recognition:} The outlier detection needs prior knowledge of normality. Using pre-labelled normal data, new incoming data can be classified as normal or abnormal. It resembles type 2 outlier detection but without the need of labelled abnormal data. This is an advantage because getting abnormal data for labelling can be difficult. However, you can’t have multiple abnormal classes. This can be a challenge in the fault detection field where knowing the type of fault is of great interest for launching an adequate recovery procedure.
\end{itemize}


%Endogenous vs Exogenous
Additionally, two strategies can be used for fault detection: endogenous fault detection and exogenous fault detection \cite{christensen2008fault, lau2012error, Miller2021modern}. Endogenous fault detection refers to the actions taken by an individual to perform fault detection on itself and on its own. While this approach is well suited for single robots, in the context of multi-robot systems, opting for this approach does not take advantage of the multiple entities close to one another forming the swarm. On the other hand, exogenous fault detection refers to the actions taken by neighbour robots on a central entity. This approach relies on the observations of multiple robots and is, as a result, better suited for swarm robotics. Exogenous data-driven fault detection methods are the best-suited for robot swarms. Exogenous strategies leverage the power of swarms: collaboration of all team members. Data-driven methods allows the detection of previously unseen faults and, as a result, enables the deployment of the swarm in unknown and dynamic environments.


%Immune system
A fault detection method inspired by the human immune system has been proposed in \cite{ tarapore2015err, tarapore2017generic}. The method uses the mathematical formulation of the cross-regulation model to distinguish between normal and abnormal behavior in a swarm of robots. Abnormality hints a fault, the abnormality being the result of the fault. The fault detection method is divided into three main phases: (i) observing the behaviors of the agents; (ii) based on the observed behaviors, perform anomaly detection using the cross-regulation model; (iii) voting to decide if the agent’s behavior is normal or abnormal.  The first phase of the method (i) uses feature vectors to characterize the behavior of an agent. The feature vector contains six features (F1, F2, F3, F4, F5, F6) with each indicating the presence (Fi=1) or absence (Fi=0) of a particular behavior. Then, the method uses these informative binary feature vectors for running the cross-regulation model. In this fault detection method, if at the end of the cross-regulation cycle, the APC (feature vector) is considered a foreign pathogen, an abnormality is inferred. Finally, in the last phase of the methods (iii) the agents consolidate their individual decisions and vote on the normal/faulty behavior of the neighboring agents. An agent that receives more than five “foreign pathogen” votes is considered faulty. The method was tested on a swarm of seven physical robots and the results showed that method was able to reliably identify the faults injected in the system \cite{tarapore2019fault}. The efficiency of method surpassed the ones of other traditional outlier detection methods K-Nearest Neighbor (KNN) and Local Outlier Factor (LOF). However, for both KNN and LOF the same binary feature vectors were used but these methods could be more effective using non-binary feature vectors. The advantage of this method is that it doesn’t require any prior knowledge of the fault to identify it. Indeed, being an outlier detection method, the presence of faults is only inferred on the presence of an abnormal behavior. This is particularly important in swarm of robots where it’s is very difficult to know in advance the potential fault that the system will encounter. It is also easier to implement. However, because the method identifies anomalies and not faults, it is very hard to perform diagnosis and recovery procedures. It is hard to know what to do when you don’t know what the problem is. \cite{okeefe2018adaptive} tackles this problem by adding a fault diagnosis layer after the fault detection one. 

%Local Outlier factor 
The Local Outlier Factor (LOF) \cite{breunig2000lof} is a measure of how much a data point can be considered an outlier. The LOF represents the density of a point compared to the density of its neighbors. A LOF around 1 means that the point is not an outlier. A LOF much higher than 1 indicates that the density of the data point is smaller the densities of the neighboring points. The data point is isolated and is, as a result, most likely to be an outlier. In summary, the higher the LOF, the most likely the data point is an outlier. 

%Neural network fault detection
A neural network fault detection approach was proposed in \cite{christensen2008faultDetection}. They suppose that the occurrence of a fault in the robotic system changes the flow of data. By monitoring the data, they can infer the presence of a fault in the system. Again, this falls into the anomaly detection category and more specifically under the data-driven approaches. They use sensor data and labelled normal/faulty data to classify the operation as being faulty or not. In each control cycle, sensor data is given as an input to the neural network (function) which outputs the state of the system {0 or 1}, where 0 correspond to not faulty and 1 to faulty. 

%Deep learning anomaly detection
In recent years, deep learning anomaly detection methods have been developed and have shown to generally outperform the traditional anomaly detection methods \cite{pang2021deep}. They are especially effective when working with complex data where traditional methods tend to struggle. 


